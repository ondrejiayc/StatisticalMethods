{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"There are only two problems in inference: how to assign probability distributions, and how to do integrals.\" - John Skilling*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The topic of how to assign priors will re-appear throughout this course, including in this week's homework.\n",
    "\n",
    "\n",
    "* One way to assign priors is to *plead ignorance.*  Not knowing the value of a parameter up to an additive constant indicates that a *uniform* (i.e. top hat) prior might be appropriate. \n",
    "\n",
    "\n",
    "* Not knowing the value of a parameter up to an multiplicative constant indicates that a prior *uniform in the log of the parameter* might be appropriate. Equating ${\\rm Pr}(x)\\,dx = {\\rm Pr}(\\log{x})\\,d \\log{x}$ and assigning the above uniform PDF leads to ${\\rm Pr}(x) \\propto 1/x$, which is sometimes known loosely as the \"Jeffreys Prior\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One problem with uninformative priors is that they can lead to parameter space volumes that are unmanageably large.\n",
    "\n",
    "#### Q:  Consider a uniform joint prior PDF in N parameter dimensions. What fraction of the *a priori* allowed volume is in a hypercubic shell that has thickness *f* of the side length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Volume fraction for f =', 0.01, ' is')\n"
     ]
    }
   ],
   "source": [
    "f = 0.01\n",
    "N = 2\n",
    "# Compute difference between two hypervolumes:\n",
    "\n",
    "print(\"Volume fraction for f =\",f,\" is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This effect can cause real computational problems when attempting to characterize posterior PDFs - you've seen it already, just in our attempts with two-dimensional grids!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informative Priors\n",
    "\n",
    "* The prior PDF is an *opportunity* - to include *more information* into our analysis.\n",
    "\n",
    "\n",
    "* One good prior PDF is the *posterior PDF* from a previous analysis.\n",
    "\n",
    "${\\rm Pr}(x|d,H) \\propto {\\rm Pr}(d|x,H)\\;{\\rm Pr}(x|c,H)$\n",
    "\n",
    "* Note that ${\\rm Pr}(x|c,H)\\propto {\\rm Pr}(c|x,H)\\;{\\rm Pr}(x|H)$ by Bayes Theorem, so that *using posteriors as priors is equivalent to joint inference from multiple datasets*:\n",
    "\n",
    "${\\rm Pr}(x|d,H) \\propto {\\rm Pr}(d|x,H)\\;{\\rm Pr}(c|x,H)\\;{\\rm Pr}(x|H)$\n",
    "\n",
    "\n",
    "* Another good prior PDF is *one that accurately represents your beliefs.* Such \"subjective priors\" are typically treated with justified caution, because scientists aspire to perform *objective* analyses. However, a prior PDF assignment is just one type of assumption in the many that are involved in the model, and they can and should be tested in the same way. We'll return to this in week 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
